{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e977990-8c4e-412d-934d-b2e4a3efb319",
   "metadata": {},
   "source": [
    "# Acquiring Article Data\n",
    "\n",
    "In this notebook we'll go through the process of acquiring all the article data that will be used in this project. The steps outlined here will allow us to replicate the process of acquiring the data, but new articles are published every day making it difficult to make fully reproduce the process of acquiring the same dataset that will be used in exploration and model training for this project. Nonetheless the steps will be outlined here for reference. A .csv file will be provided containing the data that is used for analysis and modeling for reproducibility.\n",
    "\n",
    "## Imports\n",
    "\n",
    "These are all the modules that we'll need to run the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5ede9c-d561-44b8-b77c-3239a2f0ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to add the modules directory path to sys.path since this is where all the .py files are located.\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ae2493-c3f1-4ef0-b964-a7648ff506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Medium API will be used to acquire data.\n",
    "# Medium API Documentation: https://github.com/weeping-angel/medium-api\n",
    "\n",
    "import pandas as pd\n",
    "from medium_api import Medium\n",
    "\n",
    "# We need requests and Beautiful Soup in order to scrape web data.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# We need an API key to use the Medium API. This can be acquired from rapidapi.com.\n",
    "# It is required to create an account and subscribe to the Medium API.\n",
    "# https://rapidapi.com/nishujain199719-vgIfuFHZxVZ/api/medium2/pricing\n",
    "\n",
    "from env import medium_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db6ec3-9212-460f-b8b1-b69d180d87ec",
   "metadata": {},
   "source": [
    "## Acquire Article Data Using Medium API\n",
    "\n",
    "In this section we'll cover some of the functionality provided by the Medium API. We'll discover how to use it and what can and can't be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722b0059-2c6c-48be-85c9-c82c6a433e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the Medium object with our API key, this will allow us to make calls to the API.\n",
    "\n",
    "medium = Medium(medium_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320a11c1-6b4e-40cf-9c5b-62cb924b890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try getting the latestposts for a given topic. The latestposts function only allows specifying a \n",
    "# topic.\n",
    "\n",
    "latestposts = medium.latestposts(topic_slug = 'artificial-intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebe4042a-dc1c-4bc6-8955-0a36433a20a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14f1ac7ec113',\n",
       " 'tags': ['smart-speaker',\n",
       "  'smartspeakersmarketshare',\n",
       "  'telegram',\n",
       "  'telegram-bot',\n",
       "  'voice-assistant'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:53:06',\n",
       " 'published_at': '2022-07-04 20:53:06',\n",
       " 'url': 'https://convcomp.it/could-telegram-be-a-competitor-of-voice-assistants-like-amazon-alexa-or-google-assistant-14f1ac7ec113',\n",
       " 'image_url': 'https://miro.medium.com/1*TyS9LOsSoh-506qWQURRlw.jpeg',\n",
       " 'lang': 'en',\n",
       " 'publication_id': 'e9c948ff6ebd',\n",
       " 'title': 'Could Telegram be a competitor of voice assistants, like Amazon Alexa or Google Assistant?',\n",
       " 'word_count': 2285,\n",
       " 'reading_time': 8.822641509434,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'An open letter to Pavel Durov, containing some change requests to enable voice integration into Telegram bots ecosystem',\n",
       " 'author': '452c0445f9d5'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the info for the first article in this list.\n",
    "\n",
    "latestposts.articles[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac407e5-218b-4888-b6be-ec6132f6bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fe99c68643a6',\n",
       " 'tags': ['metaverse', 'machine-learning', 'strategy', 'marketing', 'law'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:05:43',\n",
       " 'published_at': '2022-07-04 19:58:46',\n",
       " 'url': 'https://medium.com/@MetaverseLaw/metaverse-law-trends-via-machine-learning-fe99c68643a6',\n",
       " 'image_url': 'https://miro.medium.com/1*rta8P5wpi5-75cERsoJa2g.png',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '*Self-Published*',\n",
       " 'title': 'Metaverse Law Trends via Machine Learning',\n",
       " 'word_count': 3814,\n",
       " 'reading_time': 15.742452830189,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'If youâ€™re interested only in the machine learning discussion, please skip to the Machine Learning section.',\n",
       " 'author': '1506fccbdfe3'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the second article.\n",
    "\n",
    "latestposts.articles[1].info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b60b30-52bd-42df-818a-1bab25045f62",
   "metadata": {},
   "source": [
    "There was a brief delay when grabbing the info for the articles. This makes me wonder if the API is lazy and makes the call only when necessary (in this case when we call info). If this is the case then using the API, on the free tier at least, will not be possible since we will likely expend the allotted monthly API calls very rapidly. Looking at the API usage stats (at RapidAPI) it seems like this is in fact the case.\n",
    "\n",
    "The documentation shows there is a fetch_articles function that may solve this issue. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cbac4e-c52b-4d99-a355-8d684c66cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the article data using fetch_articles, this function doesn't return anything, but will instead populate\n",
    "# the latestposts.articles list.\n",
    "\n",
    "medium.fetch_articles(latestposts.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab80362-54b1-4855-bb79-7352753bc631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latestposts.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe6a927-c1a7-42b6-b036-c804c2b2d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14f1ac7ec113',\n",
       " 'tags': ['smart-speaker',\n",
       "  'smartspeakersmarketshare',\n",
       "  'telegram',\n",
       "  'telegram-bot',\n",
       "  'voice-assistant'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:53:06',\n",
       " 'published_at': '2022-07-04 20:53:06',\n",
       " 'url': 'https://convcomp.it/could-telegram-be-a-competitor-of-voice-assistants-like-amazon-alexa-or-google-assistant-14f1ac7ec113',\n",
       " 'image_url': 'https://miro.medium.com/1*TyS9LOsSoh-506qWQURRlw.jpeg',\n",
       " 'lang': 'en',\n",
       " 'publication_id': 'e9c948ff6ebd',\n",
       " 'title': 'Could Telegram be a competitor of voice assistants, like Amazon Alexa or Google Assistant?',\n",
       " 'word_count': 2285,\n",
       " 'reading_time': 8.822641509434,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'An open letter to Pavel Durov, containing some change requests to enable voice integration into Telegram bots ecosystem',\n",
       " 'author': '452c0445f9d5'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try getting the info for a few articles again.\n",
    "\n",
    "latestposts.articles[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc59f88c-536f-4597-9b53-c4db9a842359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '65de5d04c475',\n",
       " 'tags': ['artificial-intelligence',\n",
       "  'machine-learning',\n",
       "  'data-science',\n",
       "  'automation',\n",
       "  'future'],\n",
       " 'claps': 250,\n",
       " 'last_modified_at': '2022-07-04 13:10:28',\n",
       " 'published_at': '2022-07-04 12:26:24',\n",
       " 'url': 'https://medium.com/gdg-vit/ai-automation-and-the-future-of-workplaces-65de5d04c475',\n",
       " 'image_url': 'https://miro.medium.com/1*b0ig8NZnu7GBr2tZG0xnsg.png',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '7ebddf9721d',\n",
       " 'title': 'AI, Automation, and the Future of Workplaces',\n",
       " 'word_count': 1590,\n",
       " 'reading_time': 6.8333333333333,\n",
       " 'voters': 5,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'Introduction',\n",
       " 'author': '15c03e4e1b20'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latestposts.articles[10].info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46918026-f0d5-45d3-9325-1d4d4f931c67",
   "metadata": {},
   "source": [
    "There is no longer a delay when getting the article info, but the API usage stats (at RapidAPI) confirm that running the fetch_articles functions made 25 API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648fd701-9dc1-4ad1-8d0a-13e5c4c2f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3487bb252780',\n",
       " 'tags': ['coding-challenge',\n",
       "  'google',\n",
       "  'python',\n",
       "  'getting-started',\n",
       "  'programming'],\n",
       " 'claps': 10,\n",
       " 'last_modified_at': '2022-07-05 20:03:53',\n",
       " 'published_at': '2022-07-05 19:19:47',\n",
       " 'url': 'https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780',\n",
       " 'image_url': 'https://miro.medium.com/0*RX1cyqxIba1gKt1b',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '7f60cf5620c9',\n",
       " 'title': 'Google Foobar Challenge: Level 1',\n",
       " 'word_count': 1243,\n",
       " 'reading_time': 5.0738993710692,\n",
       " 'voters': 2,\n",
       " 'topics': ['data-science', 'programming'],\n",
       " 'subtitle': 'An intro to the secretive coding challenge and a breakdown of the problems',\n",
       " 'author': '94ed6e69690'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One last thing, let's try getting the information for a specific article which we know the URL of.\n",
    "# https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780\n",
    "# The article id is the series of characters at the end of the URL after the article title. 3487bb252780\n",
    "\n",
    "article = medium.article(article_id = '3487bb252780')\n",
    "article.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c5a31-9acf-4646-bc08-5fcaff453362",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Using the API would definitely make things easier, but it comes with some very significant limitations. First from the work done above we can see that for each article we collect data on the API will make a call. This means that if, for instance, we wanted to get the latest 25 articles for 5 different topics this would amount to 125 API calls which is half the monthly allotment of 250. Even using a smarter algorithm to ensure we don't make more calls than necessary we would still probably expend the monthly free tier allotment within a week.\n",
    "\n",
    "Switching to a paid tier is an option. The next tier up would cost 4.99 per month and give 1,250 API calls per month. This might be enough, but it comes with the downside of having to pay for the API. Not to mention that it might possibly still not be enough calls as the application begins to scale to a larger size. The API with the free tier would probably be good enough if this application was kept to a small scope, such as only pulling article data for 2 or 3 different topics. This would not make for a very useful application though so we may need to explore alternative solutions.\n",
    "\n",
    "It might be worthwhile to design and build a package that utilizes the API just in case later on it is discovered that the API is necessary.\n",
    "\n",
    "## Acquiring Article Data Through Web Scraping\n",
    "\n",
    "For scraping the data we need there are a few things to keep in mind.\n",
    "\n",
    "1. It is possible to structure the URL in such a way that we can get the latest articles, but without JavaScript enabled we only get 10 articles. By simply counting the number of articles published in a single day for a single topic we can expect that for most topics and publications there will likely be more than 10 articles published per day. This means we would either need to run the web scraping script multiple times a day or use a dynamic web scraping library like Selenium. I know from experience that Selenium does not play well with Crontab so this could be problematic.\n",
    "2. Getting the latest articles for a publication shouldn't be too much of an issue. Getting the latest articles for a specific topic could be problematic. Searching for a specific through the main medium site provides unusual results (the articles don't seem to be in order of most recent, articles of varying related topics seem to be returned, I also seem to get different results for Chrome and Safari).\n",
    "\n",
    "At this point I believe it is best to move forward with the solution that will be best given the limitations present. So we will only pull the latest articles for given publications and not for specific topics (at least not until this weird issue with the return results is fixed). To accomplish this task we will need requests and Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d71f943-2a1f-4553-ab1c-50559b7efb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll attempt to get the HTML for the latest articles page from towardsdatascience.com\n",
    "\n",
    "url = 'https://towardsdatascience.com/latest'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a399a1-de16-4c2e-b00f-20627096dbe5",
   "metadata": {},
   "source": [
    "For each article I would like to gather the following data:\n",
    "- Title\n",
    "- Subtitle\n",
    "- Date\n",
    "- Read Time\n",
    "- Author\n",
    "- Publication\n",
    "- URL\n",
    "- Article Intro\n",
    "\n",
    "I'll start by first getting all the article URLs on the latest article page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a193f4-2e1a-4550-9206-e2d17827160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URLs for all the latest articles.\n",
    "\n",
    "links = soup.find_all('a', title = 'Latest stories published on Towards Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cdce26-486d-4412-846a-58f1d86b2c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f31dd3c-a6f3-488f-b0ec-b2bd0b00f1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://towardsdatascience.com/navigating-mlops-dc2a242ef7ed?source=---------0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b673d4c-7523-4424-bdb5-4cda3e03f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://towardsdatascience.com/ai-can-now-play-minecraft-and-is-a-step-closer-to-navigate-the-world-1f19cfe37ef?source=---------1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[1]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7dbd6b-4012-4c17-adfa-f1689fd1093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://towardsdatascience.com/navigating-mlops-dc2a242ef7ed',\n",
       " 'https://towardsdatascience.com/ai-can-now-play-minecraft-and-is-a-step-closer-to-navigate-the-world-1f19cfe37ef',\n",
       " 'https://towardsdatascience.com/calculating-closest-landmass-between-two-points-on-earth-214f73b48fdc',\n",
       " 'https://towardsdatascience.com/visualizing-cpu-memory-and-gpu-utilities-with-python-8028d859c2b0',\n",
       " 'https://towardsdatascience.com/choosing-neural-networks-over-n-gram-models-for-natural-language-processing-156ea3a57fc',\n",
       " 'https://towardsdatascience.com/numpy-ufuncs-the-magic-behind-vectorized-functions-8cc3ba56aa2c',\n",
       " 'https://towardsdatascience.com/block-recurrent-transformer-lstm-and-transformer-combined-ec3e64af971a',\n",
       " 'https://towardsdatascience.com/5-ideas-to-create-new-features-from-polygons-f8f902f5ad8f',\n",
       " 'https://towardsdatascience.com/how-to-use-customer-lifetime-value-ltv-for-data-driven-transformation-6f12596df943',\n",
       " 'https://towardsdatascience.com/self-supervised-transformer-models-bert-gpt3-mum-and-paml-2b5e29ea0c26']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's put all the URLs into a list.\n",
    "# I'll also strip the ?source= stuff at the end of the URL.\n",
    "\n",
    "urls = [link['href'].split('?source')[0] for link in links]\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1a0d8-a496-42ba-a71c-ab05ce660bb4",
   "metadata": {},
   "source": [
    "Next we can try to gather all the data we need from a given article by scraping the webpage for that URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f4f22a-4382-4cd1-aa79-9cc8abe0529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(urls[1])\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6f7d1e-229b-4de2-b648-70bf240fd748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alberto Romero'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the author's name by searching for the class pw-author in the HTML. The author's name is then \n",
    "# three <div>s and a <a> below that.\n",
    "\n",
    "author_name = soup.find('div', class_ = 'pw-author').div.div.div.a.text\n",
    "author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc800d6-432e-4a79-a5f7-912aad198748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jul 6'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the publishing date by searching for the class pw-published-date in the HTML. The publishing \n",
    "# date is then one <span> below that.\n",
    "\n",
    "date = soup.find('p', class_ = 'pw-published-date').span.text\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c890abf0-8ce5-4d91-afec-c8cca1747698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 min read'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the read time by searching for the class pw-reading-time in the HTML.\n",
    "\n",
    "read_time = soup.find('div', class_ = 'pw-reading-time').text\n",
    "read_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e767cd01-3e13-41f4-b965-5c4acf047c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Can Now Play Minecraft â€” A Step Closer to Navigate the World'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the title by searching for the class pw-post-title in the HTML.\n",
    "\n",
    "title = soup.find('h1', class_ = 'pw-post-title').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52cf12cf-b30d-4440-be6a-3d9198c4bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The beginning of open-ended AI'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the subtitle by searching for the class pw-subtitle-paragraph in the HTML.\n",
    "\n",
    "subtitle = soup.find('h2', class_ = 'pw-subtitle-paragraph').text\n",
    "subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0923c2-c176-4541-88b4-75ba3ad55064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After building impressive models in language processing (GPT-3) and text-to-image generation (DALLÂ·E 2), OpenAI is now facing an arguably greater challenge: open-ended action. In the great task of solving so-called artificial general intelligence (AGI), they realize language and vision arenâ€™t the only domains in which AI should excel. GPT-3 and DALLÂ·E 2 are extremely good at what they do, but as powerful as they are they remain constrained within the limited boundaries of their virtual worlds.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the article intro by searching for the class \n",
    "\n",
    "article_intro = soup.find('p', class_ = 'pw-post-body-paragraph').text\n",
    "article_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d0366-feb3-4cb7-b9b8-1b8d3919577f",
   "metadata": {},
   "source": [
    "Lastly, URL and publication are both values that we would already have. The URL would have been scraped from the latest articles page and the publication will have been provided with the original URL. Now we are able to put all this information in a dictionary and add it to a pandas dataframe. Let's try this out, but run it for all the links we scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c7ea99c-240d-4314-9047-ffd8bfbbc659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>publication</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>article_intro</th>\n",
       "      <th>date</th>\n",
       "      <th>read_time</th>\n",
       "      <th>url</th>\n",
       "      <th>publication_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christian Freischlag</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Navigating MLOps in 2022</td>\n",
       "      <td>Data Science in production: experience, tools ...</td>\n",
       "      <td>MLOps has established itself as an independent...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>6 min read</td>\n",
       "      <td>https://towardsdatascience.com/navigating-mlop...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alberto Romero</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>AI Can Now Play Minecraft â€” A Step Closer to N...</td>\n",
       "      <td>The beginning of open-ended AI</td>\n",
       "      <td>After building impressive models in language p...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>7 min read</td>\n",
       "      <td>https://towardsdatascience.com/ai-can-now-play...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andrew Hershy</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Calculating Closest Landmass Between Two Point...</td>\n",
       "      <td>Python script to identify midpoint and closest...</td>\n",
       "      <td>I made some significant updates to an existing...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>5 min read</td>\n",
       "      <td>https://towardsdatascience.com/calculating-clo...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bharath K</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Visualizing CPU, Memory, And GPU Utilities wit...</td>\n",
       "      <td>Analyzing CPU, memory usage, and GPU component...</td>\n",
       "      <td>When you are indulged in programming, you are ...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>7 min read</td>\n",
       "      <td>https://towardsdatascience.com/visualizing-cpu...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benjamin McCloskey</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Choosing Neural Networks over N-Gram Models fo...</td>\n",
       "      <td>Today we will look at the strengths of using R...</td>\n",
       "      <td>Traditional learning models transform text fro...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>8 min read</td>\n",
       "      <td>https://towardsdatascience.com/choosing-neural...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diego Barba</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>NumPy ufuncs â€” The Magic Behind Vectorized Fun...</td>\n",
       "      <td>Learn about NumPy universal functions (ufuncs)...</td>\n",
       "      <td>Have you ever wondered about the origin of Num...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>7 min read</td>\n",
       "      <td>https://towardsdatascience.com/numpy-ufuncs-th...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nikos Kafritsas</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Block-Recurrent Transformer: LSTM and Transfor...</td>\n",
       "      <td>A powerful model that combines the best of bot...</td>\n",
       "      <td>The vanilla Transformer is no longer the all-m...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>12 min read</td>\n",
       "      <td>https://towardsdatascience.com/block-recurrent...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leonie Monigatti</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>5 Ideas to Create New Features from Polygons</td>\n",
       "      <td>How to Get the Area and Other Features From a ...</td>\n",
       "      <td>Polygon data can be useful in various applicat...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>6 min read</td>\n",
       "      <td>https://towardsdatascience.com/5-ideas-to-crea...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lak Lakshmanan</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>How to use Customer Lifetime Value (LTV) for d...</td>\n",
       "      <td>Use LTV to set goals for your business and dev...</td>\n",
       "      <td>If your business is undertaking a data-driven ...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>12 min read</td>\n",
       "      <td>https://towardsdatascience.com/how-to-use-cust...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Siwei Causevic</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>Self-supervised Transformer Models â€” BERT, GPT...</td>\n",
       "      <td>None</td>\n",
       "      <td>In the early days, NLP systems are mostly rule...</td>\n",
       "      <td>Jul 6</td>\n",
       "      <td>6 min read</td>\n",
       "      <td>https://towardsdatascience.com/self-supervised...</td>\n",
       "      <td>https://towardsdatascience.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author           publication  \\\n",
       "0  Christian Freischlag  Towards Data Science   \n",
       "1        Alberto Romero  Towards Data Science   \n",
       "2         Andrew Hershy  Towards Data Science   \n",
       "3             Bharath K  Towards Data Science   \n",
       "4    Benjamin McCloskey  Towards Data Science   \n",
       "5           Diego Barba  Towards Data Science   \n",
       "6       Nikos Kafritsas  Towards Data Science   \n",
       "7      Leonie Monigatti  Towards Data Science   \n",
       "8        Lak Lakshmanan  Towards Data Science   \n",
       "9        Siwei Causevic  Towards Data Science   \n",
       "\n",
       "                                               title  \\\n",
       "0                           Navigating MLOps in 2022   \n",
       "1  AI Can Now Play Minecraft â€” A Step Closer to N...   \n",
       "2  Calculating Closest Landmass Between Two Point...   \n",
       "3  Visualizing CPU, Memory, And GPU Utilities wit...   \n",
       "4  Choosing Neural Networks over N-Gram Models fo...   \n",
       "5  NumPy ufuncs â€” The Magic Behind Vectorized Fun...   \n",
       "6  Block-Recurrent Transformer: LSTM and Transfor...   \n",
       "7       5 Ideas to Create New Features from Polygons   \n",
       "8  How to use Customer Lifetime Value (LTV) for d...   \n",
       "9  Self-supervised Transformer Models â€” BERT, GPT...   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  Data Science in production: experience, tools ...   \n",
       "1                     The beginning of open-ended AI   \n",
       "2  Python script to identify midpoint and closest...   \n",
       "3  Analyzing CPU, memory usage, and GPU component...   \n",
       "4  Today we will look at the strengths of using R...   \n",
       "5  Learn about NumPy universal functions (ufuncs)...   \n",
       "6  A powerful model that combines the best of bot...   \n",
       "7  How to Get the Area and Other Features From a ...   \n",
       "8  Use LTV to set goals for your business and dev...   \n",
       "9                                               None   \n",
       "\n",
       "                                       article_intro   date    read_time  \\\n",
       "0  MLOps has established itself as an independent...  Jul 6   6 min read   \n",
       "1  After building impressive models in language p...  Jul 6   7 min read   \n",
       "2  I made some significant updates to an existing...  Jul 6   5 min read   \n",
       "3  When you are indulged in programming, you are ...  Jul 6   7 min read   \n",
       "4  Traditional learning models transform text fro...  Jul 6   8 min read   \n",
       "5  Have you ever wondered about the origin of Num...  Jul 6   7 min read   \n",
       "6  The vanilla Transformer is no longer the all-m...  Jul 6  12 min read   \n",
       "7  Polygon data can be useful in various applicat...  Jul 6   6 min read   \n",
       "8  If your business is undertaking a data-driven ...  Jul 6  12 min read   \n",
       "9  In the early days, NLP systems are mostly rule...  Jul 6   6 min read   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://towardsdatascience.com/navigating-mlop...   \n",
       "1  https://towardsdatascience.com/ai-can-now-play...   \n",
       "2  https://towardsdatascience.com/calculating-clo...   \n",
       "3  https://towardsdatascience.com/visualizing-cpu...   \n",
       "4  https://towardsdatascience.com/choosing-neural...   \n",
       "5  https://towardsdatascience.com/numpy-ufuncs-th...   \n",
       "6  https://towardsdatascience.com/block-recurrent...   \n",
       "7  https://towardsdatascience.com/5-ideas-to-crea...   \n",
       "8  https://towardsdatascience.com/how-to-use-cust...   \n",
       "9  https://towardsdatascience.com/self-supervised...   \n",
       "\n",
       "                  publication_url  \n",
       "0  https://towardsdatascience.com  \n",
       "1  https://towardsdatascience.com  \n",
       "2  https://towardsdatascience.com  \n",
       "3  https://towardsdatascience.com  \n",
       "4  https://towardsdatascience.com  \n",
       "5  https://towardsdatascience.com  \n",
       "6  https://towardsdatascience.com  \n",
       "7  https://towardsdatascience.com  \n",
       "8  https://towardsdatascience.com  \n",
       "9  https://towardsdatascience.com  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'author' : [],\n",
    "    'publication' : [],\n",
    "    'title' : [],\n",
    "    'subtitle' : [],\n",
    "    'article_intro' : [],\n",
    "    'date' : [],\n",
    "    'read_time' : [],\n",
    "    'url' : [],\n",
    "    'publication_url' : []\n",
    "})\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    article_info = {}\n",
    "    \n",
    "    article_info['author'] = [soup.find('div', class_ = 'pw-author').div.div.div.a.text]\n",
    "    article_info['publication'] = ['Towards Data Science']\n",
    "    article_info['title'] = [soup.find('h1', class_ = 'pw-post-title').text]\n",
    "    article_info['article_intro'] = [soup.find('p', class_ = 'pw-post-body-paragraph').text]\n",
    "    article_info['date'] = [soup.find('p', class_ = 'pw-published-date').span.text]\n",
    "    article_info['read_time'] = [soup.find('div', class_ = 'pw-reading-time').text]\n",
    "    article_info['url'] = [url]\n",
    "    article_info['publication_url'] = ['https://towardsdatascience.com']\n",
    "    \n",
    "    # Sometimes articles don't have a subtitle so we must check if there is a subtitle and \n",
    "    # set the subtitle to an empty string if one doesn't exist.\n",
    "    if (subtitle := soup.find('h2', class_ = 'pw-subtitle-paragraph')) is None:\n",
    "        article_info['subtitle'] = [None]\n",
    "    else:\n",
    "        article_info['subtitle'] = [subtitle.text]\n",
    "    \n",
    "    temp = pd.DataFrame(article_info)\n",
    "    df = pd.concat([df, temp]).reset_index(drop = True)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebaffaa-93b7-4d6b-ad0f-9fb377abc910",
   "metadata": {},
   "source": [
    "A quick check of these results shows that everything is correct with one exception. The date on the last article is not what is shown on the article page. Although when JavaScript is disabled the date is correct. So somehow JavaScript is changing the date after the page loads. A few checks of older articles shows that this is not because the current date is shown by default. It's weird, but for now I will ignore it.\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "Using web scraping with requests and Beautiful Soup can be enough to get all the article information needed. There are some limitations. Each scrape can get at most 10 articles. We are not able to get topic information for each article (we may need to use the API for this purpose and build a model to predict topics). Because we can only scrape 10 articles per publication we may need to run the web scraping script multiple times a day in order to keep up with the latest articles. Otherwise at some point in the future I can explore how to accomplish this with Selenium in order to deal with this issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_recommender_venv",
   "language": "python",
   "name": "article_recommender_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
