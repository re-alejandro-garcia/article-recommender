{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e977990-8c4e-412d-934d-b2e4a3efb319",
   "metadata": {},
   "source": [
    "# Acquiring Article Data\n",
    "\n",
    "In this notebook we'll go through the process of acquiring all the article data that will be used in this project. The steps outlined here will allow us to replicate the process of acquiring the data, but new articles are published every day making it difficult to make fully reproduce the process of acquiring the same dataset that will be used in exploration and model training for this project. Nonetheless the steps will be outlined here for reference. A .csv file will be provided containing the data that is used for analysis and modeling for reproducibility.\n",
    "\n",
    "## Imports\n",
    "\n",
    "These are all the modules that we'll need to run the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5ede9c-d561-44b8-b77c-3239a2f0ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to add the modules directory path to sys.path since this is where all the .py files are located.\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ae2493-c3f1-4ef0-b964-a7648ff506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Medium API will be used to acquire data.\n",
    "# Medium API Documentation: https://github.com/weeping-angel/medium-api\n",
    "\n",
    "# import pandas as pd\n",
    "from medium_api import Medium\n",
    "\n",
    "# We need requests and Beautiful Soup in order to scrape web data.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# We need an API key to use the Medium API. This can be acquired from rapidapi.com.\n",
    "# It is required to create an account and subscribe to the Medium API.\n",
    "# https://rapidapi.com/nishujain199719-vgIfuFHZxVZ/api/medium2/pricing\n",
    "\n",
    "from env import medium_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db6ec3-9212-460f-b8b1-b69d180d87ec",
   "metadata": {},
   "source": [
    "## Acquire Article Data Using Medium API\n",
    "\n",
    "In this section we'll cover some of the functionality provided by the Medium API. We'll discover how to use it and what can and can't be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722b0059-2c6c-48be-85c9-c82c6a433e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the Medium object with our API key, this will allow us to make calls to the API.\n",
    "\n",
    "medium = Medium(medium_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320a11c1-6b4e-40cf-9c5b-62cb924b890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try getting the latestposts for a given topic. The latestposts function only allows specifying a \n",
    "# topic.\n",
    "\n",
    "latestposts = medium.latestposts(topic_slug = 'artificial-intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebe4042a-dc1c-4bc6-8955-0a36433a20a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14f1ac7ec113',\n",
       " 'tags': ['smart-speaker',\n",
       "  'smartspeakersmarketshare',\n",
       "  'telegram',\n",
       "  'telegram-bot',\n",
       "  'voice-assistant'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:53:06',\n",
       " 'published_at': '2022-07-04 20:53:06',\n",
       " 'url': 'https://convcomp.it/could-telegram-be-a-competitor-of-voice-assistants-like-amazon-alexa-or-google-assistant-14f1ac7ec113',\n",
       " 'image_url': 'https://miro.medium.com/1*TyS9LOsSoh-506qWQURRlw.jpeg',\n",
       " 'lang': 'en',\n",
       " 'publication_id': 'e9c948ff6ebd',\n",
       " 'title': 'Could Telegram be a competitor of voice assistants, like Amazon Alexa or Google Assistant?',\n",
       " 'word_count': 2285,\n",
       " 'reading_time': 8.822641509434,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'An open letter to Pavel Durov, containing some change requests to enable voice integration into Telegram bots ecosystem',\n",
       " 'author': '452c0445f9d5'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the info for the first article in this list.\n",
    "\n",
    "latestposts.articles[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac407e5-218b-4888-b6be-ec6132f6bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fe99c68643a6',\n",
       " 'tags': ['metaverse', 'machine-learning', 'strategy', 'marketing', 'law'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:05:43',\n",
       " 'published_at': '2022-07-04 19:58:46',\n",
       " 'url': 'https://medium.com/@MetaverseLaw/metaverse-law-trends-via-machine-learning-fe99c68643a6',\n",
       " 'image_url': 'https://miro.medium.com/1*rta8P5wpi5-75cERsoJa2g.png',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '*Self-Published*',\n",
       " 'title': 'Metaverse Law Trends via Machine Learning',\n",
       " 'word_count': 3814,\n",
       " 'reading_time': 15.742452830189,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'If youâ€™re interested only in the machine learning discussion, please skip to the Machine Learning section.',\n",
       " 'author': '1506fccbdfe3'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the second article.\n",
    "\n",
    "latestposts.articles[1].info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b60b30-52bd-42df-818a-1bab25045f62",
   "metadata": {},
   "source": [
    "There was a brief delay when grabbing the info for the articles. This makes me wonder if the API is lazy and makes the call only when necessary (in this case when we call info). If this is the case then using the API, on the free tier at least, will not be possible since we will likely expend the allotted monthly API calls very rapidly. Looking at the API usage stats (at RapidAPI) it seems like this is in fact the case.\n",
    "\n",
    "The documentation shows there is a fetch_articles function that may solve this issue. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cbac4e-c52b-4d99-a355-8d684c66cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the article data using fetch_articles, this function doesn't return anything, but will instead populate\n",
    "# the latestposts.articles list.\n",
    "\n",
    "medium.fetch_articles(latestposts.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab80362-54b1-4855-bb79-7352753bc631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latestposts.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe6a927-c1a7-42b6-b036-c804c2b2d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14f1ac7ec113',\n",
       " 'tags': ['smart-speaker',\n",
       "  'smartspeakersmarketshare',\n",
       "  'telegram',\n",
       "  'telegram-bot',\n",
       "  'voice-assistant'],\n",
       " 'claps': 0,\n",
       " 'last_modified_at': '2022-07-04 20:53:06',\n",
       " 'published_at': '2022-07-04 20:53:06',\n",
       " 'url': 'https://convcomp.it/could-telegram-be-a-competitor-of-voice-assistants-like-amazon-alexa-or-google-assistant-14f1ac7ec113',\n",
       " 'image_url': 'https://miro.medium.com/1*TyS9LOsSoh-506qWQURRlw.jpeg',\n",
       " 'lang': 'en',\n",
       " 'publication_id': 'e9c948ff6ebd',\n",
       " 'title': 'Could Telegram be a competitor of voice assistants, like Amazon Alexa or Google Assistant?',\n",
       " 'word_count': 2285,\n",
       " 'reading_time': 8.822641509434,\n",
       " 'voters': 0,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'An open letter to Pavel Durov, containing some change requests to enable voice integration into Telegram bots ecosystem',\n",
       " 'author': '452c0445f9d5'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try getting the info for a few articles again.\n",
    "\n",
    "latestposts.articles[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc59f88c-536f-4597-9b53-c4db9a842359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '65de5d04c475',\n",
       " 'tags': ['artificial-intelligence',\n",
       "  'machine-learning',\n",
       "  'data-science',\n",
       "  'automation',\n",
       "  'future'],\n",
       " 'claps': 250,\n",
       " 'last_modified_at': '2022-07-04 13:10:28',\n",
       " 'published_at': '2022-07-04 12:26:24',\n",
       " 'url': 'https://medium.com/gdg-vit/ai-automation-and-the-future-of-workplaces-65de5d04c475',\n",
       " 'image_url': 'https://miro.medium.com/1*b0ig8NZnu7GBr2tZG0xnsg.png',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '7ebddf9721d',\n",
       " 'title': 'AI, Automation, and the Future of Workplaces',\n",
       " 'word_count': 1590,\n",
       " 'reading_time': 6.8333333333333,\n",
       " 'voters': 5,\n",
       " 'topics': ['artificial-intelligence'],\n",
       " 'subtitle': 'Introduction',\n",
       " 'author': '15c03e4e1b20'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latestposts.articles[10].info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46918026-f0d5-45d3-9325-1d4d4f931c67",
   "metadata": {},
   "source": [
    "There is no longer a delay when getting the article info, but the API usage stats (at RapidAPI) confirm that running the fetch_articles functions made 25 API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648fd701-9dc1-4ad1-8d0a-13e5c4c2f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3487bb252780',\n",
       " 'tags': ['coding-challenge',\n",
       "  'google',\n",
       "  'python',\n",
       "  'getting-started',\n",
       "  'programming'],\n",
       " 'claps': 10,\n",
       " 'last_modified_at': '2022-07-05 20:03:53',\n",
       " 'published_at': '2022-07-05 19:19:47',\n",
       " 'url': 'https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780',\n",
       " 'image_url': 'https://miro.medium.com/0*RX1cyqxIba1gKt1b',\n",
       " 'lang': 'en',\n",
       " 'publication_id': '7f60cf5620c9',\n",
       " 'title': 'Google Foobar Challenge: Level 1',\n",
       " 'word_count': 1243,\n",
       " 'reading_time': 5.0738993710692,\n",
       " 'voters': 2,\n",
       " 'topics': ['data-science', 'programming'],\n",
       " 'subtitle': 'An intro to the secretive coding challenge and a breakdown of the problems',\n",
       " 'author': '94ed6e69690'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One last thing, let's try getting the information for a specific article which we know the URL of.\n",
    "# https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780\n",
    "# The article id is the series of characters at the end of the URL after the article title. 3487bb252780\n",
    "\n",
    "article = medium.article(article_id = '3487bb252780')\n",
    "article.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c5a31-9acf-4646-bc08-5fcaff453362",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Using the API would definitely make things easier, but it comes with some very significant limitations. First from the work done above we can see that for each article we collect data on the API will make a call. This means that if, for instance, we wanted to get the latest 25 articles for 5 different topics this would amount to 125 API calls which is half the monthly allotment of 250. Even using a smarter algorithm to ensure we don't make more calls than necessary we would still probably expend the monthly free tier allotment within a week.\n",
    "\n",
    "Switching to a paid tier is an option. The next tier up would cost 4.99 per month and give 1,250 API calls per month. This might be enough, but it comes with the downside of having to pay for the API. Not to mention that it might possibly still not be enough calls as the application begins to scale to a larger size. The API with the free tier would probably be good enough if this application was kept to a small scope, such as only pulling article data for 2 or 3 different topics. This would not make for a very useful application though so we may need to explore alternative solutions.\n",
    "\n",
    "It might be worthwhile to design and build a package that utilizes the API just in case later on it is discovered that the API is necessary.\n",
    "\n",
    "## Acquiring Article Data Through Web Scraping\n",
    "\n",
    "For scraping the data we need there are a few things to keep in mind.\n",
    "\n",
    "1. It is possible to structure the URL in such a way that we can get the latest articles, but without JavaScript enabled we only get 10 articles. By simply counting the number of articles published in a single day for a single topic we can expect that for most topics and publications there will likely be more than 10 articles published per day. This means we would either need to run the web scraping script multiple times a day or use a dynamic web scraping library like Selenium. I know from experience that Selenium does not play well with Crontab so this could be problematic.\n",
    "2. Getting the latest articles for a publication shouldn't be too much of an issue. Getting the latest articles for a specific topic could be problematic. Searching for a specific through the main medium site provides unusual results (the articles don't seem to be in order of most recent, articles of varying related topics seem to be returned, I also seem to get different results for Chrome and Safari).\n",
    "\n",
    "At this point I believe it is best to move forward with the solution that will be best given the limitations present. So we will only pull the latest articles for given publications and not for specific topics (at least not until this weird issue with the return results is fixed). To accomplish this task we will need requests and Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d71f943-2a1f-4553-ab1c-50559b7efb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll attempt to get the HTML for the latest articles page from towardsdatascience.com\n",
    "\n",
    "url = 'https://towardsdatascience.com/latest'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a399a1-de16-4c2e-b00f-20627096dbe5",
   "metadata": {},
   "source": [
    "For each article I would like to gather the following data:\n",
    "- Title\n",
    "- Subtitle\n",
    "- Date\n",
    "- Read Time\n",
    "- Author\n",
    "- Publication\n",
    "- URL\n",
    "- Article Intro\n",
    "\n",
    "I'll start by first getting all the article URLs on the latest article page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a193f4-2e1a-4550-9206-e2d17827160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URLs for all the latest articles.\n",
    "\n",
    "links = soup.find_all('a', title = 'Latest stories published on Towards Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3cdce26-486d-4412-846a-58f1d86b2c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f31dd3c-a6f3-488f-b0ec-b2bd0b00f1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://towardsdatascience.com/introducing-snapshot-testing-for-jupyter-notebooks-896512971df8?source=---------0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b673d4c-7523-4424-bdb5-4cda3e03f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780?source=---------1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[1]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7dbd6b-4012-4c17-adfa-f1689fd1093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://towardsdatascience.com/introducing-snapshot-testing-for-jupyter-notebooks-896512971df8',\n",
       " 'https://towardsdatascience.com/google-foobar-challenge-level-1-3487bb252780',\n",
       " 'https://towardsdatascience.com/how-to-create-a-graph-neural-network-in-python-61fd9b83b54e',\n",
       " 'https://towardsdatascience.com/using-bayesian-statistics-to-predict-cafes-popularity-with-geodata-3286deaffc2',\n",
       " 'https://towardsdatascience.com/how-i-landed-an-amazon-sde-internship-without-a-computer-science-degree-85596c480d4d',\n",
       " 'https://towardsdatascience.com/geo-lift-experiments-ii-spotify-blend-case-study-476a81099744',\n",
       " 'https://towardsdatascience.com/computer-vision-convolution-basics-2d0ae3b79346',\n",
       " 'https://towardsdatascience.com/visualizing-cannabis-sales-and-cost-ddd35c2402b1',\n",
       " 'https://towardsdatascience.com/pyscript-v-flask-how-to-create-a-python-app-in-the-browser-or-on-a-server-2cfe4dd0df9d',\n",
       " 'https://towardsdatascience.com/k-nearest-neighbors-naive-bayes-and-decision-tree-in-10-minutes-f8620b25e89b']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's put all the URLs into a list.\n",
    "# I'll also strip the ?source= stuff at the end of the URL.\n",
    "\n",
    "urls = [link['href'].split('?source')[0] for link in links]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3126c5f-b95b-4354-9bab-bef1ddaf4d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_recommender_venv",
   "language": "python",
   "name": "article_recommender_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
